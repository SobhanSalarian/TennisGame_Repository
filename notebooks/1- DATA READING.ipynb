{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749a7798",
   "metadata": {},
   "source": [
    "# Tennis Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429ae71",
   "metadata": {},
   "source": [
    "## Data Reading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9163527",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Manulay extracting 202405.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86b1ba",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Extracting 31 zip files inside the main directory in another location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca9f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_files_directory = '../data/rawTest'\n",
    "\n",
    "extract_to_directory = '../data/raw'\n",
    "\n",
    "# Iterate over all files in the zip files directory\n",
    "for filename in os.listdir(zip_files_directory):\n",
    "    if filename.endswith('.zip'):\n",
    "        zip_file_path = os.path.join(zip_files_directory, filename)\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            # Create a sub-directory for each zip file based on the zip file name\n",
    "            sub_directory = os.path.join(extract_to_directory, os.path.splitext(filename)[0])\n",
    "            if not os.path.exists(sub_directory):\n",
    "                os.makedirs(sub_directory)\n",
    "            zip_ref.extractall(sub_directory)\n",
    "            #print(f\"Extracted {filename} to {sub_directory}\")\n",
    "\n",
    "print(\"All files have been extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853f803",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "Creating a dictionary of empty dataframes, \n",
    "importing required libraries, and \n",
    "get access to the parquet files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf14210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Directory containing the extracted files\n",
    "extracted_files_directory = '../data/raw'\n",
    "\n",
    "# Initialize empty DataFrames\n",
    "data_frames = {\n",
    "    'MatchEventInfo': pd.DataFrame(),\n",
    "    'PeriodInfo': pd.DataFrame(),\n",
    "    'MatchVotesInfo': pd.DataFrame(),\n",
    "    'MatchTournamentInfo': pd.DataFrame(),\n",
    "    'MatchSeasonInfo': pd.DataFrame(),\n",
    "    'MatchRoundInfo': pd.DataFrame(),\n",
    "    'MatchVenueInfo': pd.DataFrame(),\n",
    "    'MatchHomeTeamInfo': pd.DataFrame(),\n",
    "    'MatchAwayTeamInfo': pd.DataFrame(),\n",
    "    'MatchHomeScoreInfo': pd.DataFrame(),\n",
    "    'MatchAwayScoreInfo': pd.DataFrame(),\n",
    "    'MatchTimeInfo': pd.DataFrame(),\n",
    "    'GameInfo': pd.DataFrame(),\n",
    "    'OddsInfo': pd.DataFrame(),\n",
    "    'PowerInfo': pd.DataFrame()\n",
    "}\n",
    "\n",
    "# Function to process Parquet files and append data to the corresponding DataFrame\n",
    "def process_parquet_file(parquet_file_path, data_frames):\n",
    "    # Extract the file name\n",
    "    file_name = os.path.basename(parquet_file_path)\n",
    "    \n",
    "    # Check which DataFrame to append to based on the file name prefix\n",
    "    if file_name.startswith('event'):\n",
    "        df_key = 'MatchEventInfo'\n",
    "    elif file_name.startswith('pbp'):\n",
    "        df_key = 'PeriodInfo'\n",
    "    elif file_name.startswith('votes'):\n",
    "        df_key = 'MatchVotesInfo'\n",
    "    elif file_name.startswith('tournament'):\n",
    "        df_key = 'MatchTournamentInfo'\n",
    "    elif file_name.startswith('season'):\n",
    "        df_key = 'MatchSeasonInfo'\n",
    "    elif file_name.startswith('round'):\n",
    "        df_key = 'MatchRoundInfo'\n",
    "    elif file_name.startswith('venue'):\n",
    "        df_key = 'MatchVenueInfo'\n",
    "    elif file_name.startswith('home_team_1'):\n",
    "        df_key = 'MatchHomeTeamInfo'\n",
    "    elif file_name.startswith('away_team_1'):\n",
    "        df_key = 'MatchAwayTeamInfo'\n",
    "    elif file_name.startswith('home_team_score'):\n",
    "        df_key = 'MatchHomeScoreInfo'\n",
    "    elif file_name.startswith('away_team_score'):\n",
    "        df_key = 'MatchAwayScoreInfo'\n",
    "    elif file_name.startswith('time'):\n",
    "        df_key = 'MatchTimeInfo'\n",
    "    elif file_name.startswith('statistics'):\n",
    "        df_key = 'GameInfo'\n",
    "    elif file_name.startswith('odds'):\n",
    "        df_key = 'OddsInfo'\n",
    "    elif file_name.startswith('power'):\n",
    "        df_key = 'PowerInfo'\n",
    "    else:\n",
    "        print(f\"Unknown file prefix for {file_name}, skipping file.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "    data_frames[df_key] = pd.concat([data_frames[df_key], df], ignore_index=True)\n",
    "    print(f\"Appended data from {file_name} to {df_key}\")\n",
    "\n",
    "# Traverse through the extracted files directory\n",
    "for root, dirs, files in os.walk(extracted_files_directory):\n",
    "    for dir_name in dirs:\n",
    "        if dir_name.endswith('_parquet'):\n",
    "            parquet_folder_path = os.path.join(root, dir_name)\n",
    "            for root2, dirs2, files2 in os.walk(parquet_folder_path):\n",
    "                for file_name in files2:\n",
    "                    if file_name.endswith('.parquet'):\n",
    "                        parquet_file_path = os.path.join(root2, file_name)\n",
    "                        process_parquet_file(parquet_file_path, data_frames)\n",
    "    \n",
    "\n",
    "# print(\"All Parquet files have been processed.\")\n",
    "\n",
    "# Verify the data\n",
    "for key, df in data_frames.items():\n",
    "    print(f\"{key} DataFrame shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fc76c",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "Save all  dataframes into csv format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c96e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory='../data/processed'\n",
    "for key, unique_data in data_frames.items():\n",
    "    file_path = os.path.join(output_directory, f\"{key}.csv\")\n",
    "    unique_data.to_csv(file_path, index=False)\n",
    "    print(f\"Saved {key} to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
